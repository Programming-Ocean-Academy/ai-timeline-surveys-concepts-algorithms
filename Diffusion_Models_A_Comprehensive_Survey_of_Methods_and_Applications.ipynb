{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![citations.jpg](data:image/jpeg;base64,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)\n",
        "# Ling Yang"
      ],
      "metadata": {
        "id": "ufJyqgw1K7Eg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Diffusion Models: A Comprehensive Survey of Methods and Applications\n",
        "\n",
        "# https://arxiv.org/pdf/2209.00796\n",
        "\n",
        "## Abstract\n",
        "This paper presents a comprehensive survey of diffusion models as a class of generative models that construct complex data distributions through iterative denoising processes. It unifies denoising diffusion probabilistic models, score-based generative models, and stochastic differential equation formulations under a common theoretical framework. The survey systematically reviews foundational principles, training objectives, sampling strategies, likelihood improvements, structural extensions, and a wide range of applications across vision, language, multimodal generation, temporal data, and scientific domains.\n",
        "\n",
        "## Problems\n",
        "The paper identifies several core challenges in diffusion modeling:\n",
        "1. **Sampling inefficiency** due to the large number of denoising steps required for high-quality generation.\n",
        "2. **Suboptimal likelihood estimation**, as the variational lower bound used in training may be loose.\n",
        "3. **Limited adaptability to structured data**, including discrete spaces, manifolds, equivariant domains, and graphs.\n",
        "4. **Fragmentation of theory**, with multiple formulations (DDPMs, score matching, SDEs) historically treated as separate models.\n",
        "5. **Practical deployment barriers**, including high computational cost and difficulty in conditioning and control.\n",
        "\n",
        "## Proposed Solutions\n",
        "The survey organizes existing solutions into coherent categories:\n",
        "- Efficient sampling via deterministic solvers, truncated diffusion, optimized discretization, and knowledge distillation.\n",
        "- Likelihood improvement through noise schedule optimization, reverse variance learning, and exact likelihood computation.\n",
        "- Structural extensions for discrete data, invariant and equivariant data, and manifold-constrained domains.\n",
        "- Unified theoretical treatment connecting diffusion models with VAEs, GANs, normalizing flows, autoregressive models, and energy-based models.\n",
        "- Advanced conditioning mechanisms, including classifier-free guidance, multimodal conditioning, and reinforcement learning–based alignment.\n",
        "\n",
        "## Purpose\n",
        "The primary purpose of the paper is to provide a unified, systematic, and up-to-date reference on diffusion models. It aims to clarify theoretical foundations, categorize methodological advances, and highlight practical design principles, thereby serving both as an entry point for newcomers and a consolidation resource for experienced researchers.\n",
        "\n",
        "## Methodology\n",
        "The authors conduct a structured literature review, organizing diffusion research along:\n",
        "- **Modeling foundations**: DDPMs, score-based models, and SDE formulations.\n",
        "- **Algorithmic improvements**: sampling acceleration and likelihood optimization.\n",
        "- **Data structure adaptations**: discrete spaces, graphs, manifolds, and equivariant settings.\n",
        "- **Connections to other generative paradigms**.\n",
        "- **Applications** across computer vision, natural language processing, multimodal generation, time series, robustness, and scientific modeling.\n",
        "The analysis is comparative and conceptual, emphasizing unifying principles rather than proposing a new algorithm.\n",
        "\n",
        "## Results\n",
        "The survey demonstrates that diffusion models:\n",
        "- Achieve state-of-the-art performance across many generative tasks, often surpassing GANs in stability and sample quality.\n",
        "- Offer exceptional flexibility in conditioning and control compared to autoregressive models.\n",
        "- Naturally extend to diverse data modalities, including images, videos, 3D data, graphs, molecules, proteins, audio, and time series.\n",
        "- Provide strong theoretical links to energy-based modeling and stochastic processes, enabling principled extensions and analysis.\n",
        "\n",
        "## Conclusions\n",
        "The paper concludes that diffusion models represent a foundational paradigm in modern generative modeling, combining theoretical rigor with empirical success. While computational efficiency remains a challenge, ongoing advances in sampling, distillation, and model design are rapidly improving practicality. The authors position diffusion models as a unifying framework that bridges classical probabilistic modeling and modern deep learning, with broad implications for future research and real-world applications.\n"
      ],
      "metadata": {
        "id": "fpJnuxidJASH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Forward Diffusion Process (Noise Injection)\n",
        "\n",
        "### Mathematical formulation\n",
        "\n",
        "The data is progressively corrupted by Gaussian noise via a Markov chain:\n",
        "$$\n",
        "q(x_t \\mid x_{t-1})=\\mathcal{N}\\big(\\sqrt{1-\\beta_t}\\,x_{t-1},\\ \\beta_t I\\big).\n",
        "$$\n",
        "\n",
        "Closed-form marginal:\n",
        "$$\n",
        "q(x_t \\mid x_0)=\\mathcal{N}\\big(\\sqrt{\\bar{\\alpha}_t}\\,x_0,\\ (1-\\bar{\\alpha}_t)I\\big),\n",
        "$$\n",
        "where\n",
        "$$\n",
        "\\alpha_t = 1-\\beta_t,\\qquad \\bar{\\alpha}_t=\\prod_{i=1}^{t}\\alpha_i.\n",
        "$$\n",
        "\n",
        "### Explanation\n",
        "\n",
        "This defines how data is gradually destroyed into pure noise. The process is fixed (non-learned), and the Gaussian structure keeps the distributions tractable.\n",
        "\n",
        "### Role\n",
        "\n",
        "Establishes the forward (noising) process that makes it possible to learn the reverse generative process.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Reverse Diffusion Process (Generative Model)\n",
        "\n",
        "### Mathematical formulation\n",
        "\n",
        "The reverse process is learned:\n",
        "$$\n",
        "p_\\theta(x_{t-1}\\mid x_t)=\\mathcal{N}\\big(\\mu_\\theta(x_t,t),\\ \\Sigma_\\theta(x_t,t)\\big).\n",
        "$$\n",
        "\n",
        "Common parameterization using noise prediction:\n",
        "$$\n",
        "\\mu_\\theta(x_t,t)=\\frac{1}{\\sqrt{\\alpha_t}}\\left(x_t-\\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}\\ \\epsilon_\\theta(x_t,t)\\right).\n",
        "$$\n",
        "\n",
        "### Explanation\n",
        "\n",
        "The model learns to undo noise step-by-step. Predicting noise is typically more stable than predicting $x_0$ directly.\n",
        "\n",
        "### Role\n",
        "\n",
        "Defines the core generative mechanism of DDPM-style diffusion models.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Training Objective (Variational Lower Bound)\n",
        "\n",
        "### Mathematical formulation\n",
        "\n",
        "Evidence Lower Bound (ELBO):\n",
        "$$\n",
        "\\log p_\\theta(x_0)\\ \\ge\\ \\mathbb{E}_{q}\\left[\\sum_{t=1}^{T}\\mathrm{KL}\\big(q(x_{t-1}\\mid x_t,x_0)\\ \\|\\ p_\\theta(x_{t-1}\\mid x_t)\\big)\\right].\n",
        "$$\n",
        "\n",
        "Often simplified to an MSE loss on noise prediction:\n",
        "$$\n",
        "\\mathcal{L}_{\\text{simple}}=\\mathbb{E}_{x_0,t,\\epsilon}\\left[\\left\\|\\epsilon-\\epsilon_\\theta(x_t,t)\\right\\|^2\\right].\n",
        "$$\n",
        "\n",
        "### Explanation\n",
        "\n",
        "Training minimizes the difference between true noise and predicted noise, avoiding direct likelihood computation in practice.\n",
        "\n",
        "### Role\n",
        "\n",
        "Shows diffusion training as variational inference with a practical denoising (noise-prediction) objective.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Score Matching Interpretation\n",
        "\n",
        "### Mathematical formulation\n",
        "\n",
        "Score function:\n",
        "$$\n",
        "s(x_t,t)=\\nabla_{x_t}\\log q(x_t).\n",
        "$$\n",
        "\n",
        "Relation to noise prediction (typical form):\n",
        "$$\n",
        "s_\\theta(x_t,t)= -\\frac{1}{\\sigma_t}\\ \\epsilon_\\theta(x_t,t).\n",
        "$$\n",
        "\n",
        "### Explanation\n",
        "\n",
        "The network learns a proxy for the gradient of the log-density, connecting diffusion to score matching.\n",
        "\n",
        "### Role\n",
        "\n",
        "Unifies DDPMs with score-based generative modeling (SGMs).\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Langevin Dynamics (Sampling)\n",
        "\n",
        "### Mathematical formulation\n",
        "\n",
        "Annealed Langevin Dynamics update:\n",
        "$$\n",
        "x^{(i+1)} = x^{(i)} + \\frac{1}{2}s_t\\, s_\\theta(x^{(i)},t) + s_t\\,\\epsilon^{(i)},\n",
        "\\qquad \\epsilon^{(i)}\\sim\\mathcal{N}(0,I).\n",
        "$$\n",
        "\n",
        "### Explanation\n",
        "\n",
        "Uses score estimates to move toward higher density while injecting noise to ensure exploration.\n",
        "\n",
        "### Role\n",
        "\n",
        "One of the early sampling approaches for score-based models.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Continuous-Time Diffusion (Score SDEs)\n",
        "\n",
        "### Mathematical formulation\n",
        "\n",
        "Forward SDE:\n",
        "$$\n",
        "dx = f(x,t)\\,dt + g(t)\\,dw.\n",
        "$$\n",
        "\n",
        "Reverse-time SDE:\n",
        "$$\n",
        "dx=\\left[f(x,t)-g(t)^2\\nabla_x\\log p_t(x)\\right]dt + g(t)\\,d\\bar{w}.\n",
        "$$\n",
        "\n",
        "### Explanation\n",
        "\n",
        "Generalizes diffusion to continuous time, enabling flexible noise schedules and linking to numerical solvers.\n",
        "\n",
        "### Role\n",
        "\n",
        "Provides a unified SDE framework covering many diffusion variants.\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Probability Flow ODE\n",
        "\n",
        "### Mathematical formulation\n",
        "$$\n",
        "dx=\\left[f(x,t)-\\frac{1}{2}g(t)^2\\nabla_x\\log p_t(x)\\right]dt.\n",
        "$$\n",
        "\n",
        "### Explanation\n",
        "\n",
        "A deterministic alternative to SDE sampling that can enable likelihood computation under certain conditions.\n",
        "\n",
        "### Role\n",
        "\n",
        "Conceptual foundation for fast deterministic samplers (e.g., DDIM-style ideas) and ODE-based solvers.\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Connections to Variational Autoencoders (VAEs)\n",
        "\n",
        "### Mathematical formulation\n",
        "\n",
        "VAE ELBO:\n",
        "$$\n",
        "\\mathcal{L}=\\mathbb{E}_{q_\\phi(z\\mid x)}\\big[\\log p_\\theta(x\\mid z)\\big]\n",
        "-\\mathrm{KL}\\big(q_\\phi(z\\mid x)\\ \\|\\ p(z)\\big).\n",
        "$$\n",
        "\n",
        "Diffusion interpretation (conceptual mapping):\n",
        "- Forward diffusion $\\approx$ fixed encoder\n",
        "- Reverse diffusion $\\approx$ shared decoder across many latent steps\n",
        "\n",
        "### Explanation\n",
        "\n",
        "Diffusion can be viewed as a hierarchical latent-variable model with many latent variables and a structured inference/generation process.\n",
        "\n",
        "### Role\n",
        "\n",
        "Clarifies links between diffusion and classical latent-variable generative modeling.\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Schrödinger Bridge and Optimal Transport\n",
        "\n",
        "### Mathematical concept\n",
        "\n",
        "Find the most likely stochastic process connecting two distributions, often related to entropy-regularized optimal transport.\n",
        "\n",
        "### Explanation\n",
        "\n",
        "Motivates approaches that reduce the number of diffusion steps while preserving distributional correctness.\n",
        "\n",
        "### Role\n",
        "\n",
        "Inspires newer diffusion variants targeting finite-time or more efficient convergence.\n",
        "\n",
        "---\n",
        "\n",
        "## 10. High-Order Score Matching\n",
        "\n",
        "### Mathematical concept\n",
        "\n",
        "Estimating higher-order derivatives of the log-density:\n",
        "$$\n",
        "\\nabla^k \\log p(x).\n",
        "$$\n",
        "\n",
        "### Explanation\n",
        "\n",
        "Captures richer local geometry of the data distribution, potentially improving mixing and sampling efficiency.\n",
        "\n",
        "### Role\n",
        "\n",
        "Addresses slow convergence issues in gradient-based (Langevin-like) sampling.\n",
        "\n",
        "---\n",
        "\n",
        "## Summary Table (Mental Model)\n",
        "\n",
        "| Concept | Mathematical tool | Purpose |\n",
        "|---|---|---|\n",
        "| Forward diffusion | Gaussian Markov chain | Destroy data into noise |\n",
        "| Reverse diffusion | Learned conditional Gaussian | Generate data by denoising |\n",
        "| Training | Variational inference (ELBO) | Learn the reverse process |\n",
        "| Score matching | Gradient of log-density | Unifying interpretation |\n",
        "| Sampling | Langevin / ODE | Draw samples |\n",
        "| SDEs | Stochastic calculus | Continuous-time modeling |\n",
        "| VAEs | ELBO | Structural connection |\n",
        "| Schrödinger bridge | Optimal transport | Faster convergence ideas |\n",
        "| High-order scores | Higher derivatives | Better geometry, faster mixing |\n",
        "\n",
        "---\n",
        "\n",
        "## Final Insight\n",
        "\n",
        "Diffusion models unify multiple mathematical ideas into one probabilistic framework:\n",
        "- stochastic processes,\n",
        "- variational inference,\n",
        "- score matching,\n",
        "- Monte Carlo sampling,\n",
        "- differential equations,\n",
        "\n",
        "yielding a method that is both theoretically grounded and empirically strong.\n"
      ],
      "metadata": {
        "id": "jHMzNJwsKp63"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Research Problem / Gap | How It Limits Prior Work | How the Paper Addresses It |\n",
        "|------------------------|--------------------------|-----------------------------|\n",
        "| Fragmented theoretical foundations of diffusion models | Prior work treats DDPMs, score-based models, and SDE-based formulations as separate paradigms, making it difficult to compare methods or transfer insights across frameworks | The paper unifies these models under a single probabilistic framework, showing their equivalence through variational inference and stochastic differential equations |\n",
        "| High computational cost and slow sampling | Many diffusion models require hundreds or thousands of denoising steps, limiting scalability and real-world deployment | The paper surveys accelerated sampling techniques, including deterministic solvers, probability flow ODEs, truncation strategies, and distillation methods |\n",
        "| Loose likelihood bounds and inefficient training objectives | Variational lower bounds used in early diffusion models can be suboptimal, leading to inefficient learning and inaccurate likelihood estimates | The paper reviews improved noise schedules, variance learning, and alternative likelihood formulations that tighten bounds and improve training stability |\n",
        "| Limited support for discrete, structured, and constrained data | Classical diffusion formulations assume continuous Euclidean spaces, restricting applicability to text, graphs, categorical variables, and manifolds | The paper consolidates extensions of diffusion models to discrete spaces, graphs, equivariant domains, and manifold-constrained data |\n",
        "| Weak theoretical connection to other generative models | Prior generative frameworks (GANs, VAEs, normalizing flows, EBMs) are often studied in isolation, obscuring shared principles | The paper explicitly establishes mathematical and conceptual links between diffusion models and other generative paradigms |\n",
        "| Difficulty in conditioning, control, and alignment | Earlier diffusion models offered limited mechanisms for guided generation and alignment with human intent | The paper reviews classifier guidance, classifier-free guidance, multimodal conditioning, and reinforcement-learning-based alignment approaches |\n",
        "| Lack of a consolidated reference for applications | Applications of diffusion models are scattered across domains, making it hard to assess their generality | The paper provides a systematic taxonomy of applications across vision, language, multimodal generation, time series, robustness, and scientific modeling |\n",
        "\n"
      ],
      "metadata": {
        "id": "3biIXgywLO7S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References Table\n",
        "\n",
        "| # | Paper Title | Year |\n",
        "|---|------------|------|\n",
        "| 1 | GPT-4 Technical Report | 2023 |\n",
        "| 2 | Building Normalizing Flows with Stochastic Interpolants | 2022 |\n",
        "| 3 | Diffusion-based Time Series Imputation and Forecasting with Structured State Space Models | 2022 |\n",
        "| 4 | SegDiff: Image Segmentation with Diffusion Probabilistic Models | 2021 |\n",
        "| 5 | Protein Structure and Sequence Generation with Equivariant Denoising Diffusion Probabilistic Models | 2022 |\n",
        "| 6 | Reverse-Time Diffusion Equation Models | 1982 |\n",
        "| 7 | PaLM 2 Technical Report | 2023 |\n",
        "| 8 | Computer Methods for Ordinary Differential Equations and Differential-Algebraic Equations | 1998 |\n",
        "| 9 | Structured Denoising Diffusion Models in Discrete State-Spaces | 2021 |\n",
        "|10 | Blended Diffusion for Text-Driven Editing of Natural Images | 2022 |\n",
        "|11 | Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback | 2022 |\n",
        "|12 | Leaving Reality to Imagination: Robust Classification via Generated Datasets | 2023 |\n",
        "|13 | Analytic-DPM: An Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models | 2021 |\n",
        "|14 | One Transformer Fits All Distributions in Multi-Modal Diffusion at Scale | 2023 |\n",
        "|15 | Label-Efficient Semantic Segmentation with Diffusion Models | 2021 |\n",
        "|16 | Conditional Image Generation with Score-Based Diffusion Models | 2021 |\n",
        "|17 | Taking on the Curse of Dimensionality in Joint Distributions Using Neural Networks | 2000 |\n",
        "|18 | A Neural Probabilistic Language Model | 2003 |\n",
        "|19 | The Protein Data Bank | 2000 |\n",
        "|20 | Improving Image Generation with Better Captions | 2023 |\n",
        "|21 | Graph Barlow Twins: A Self-Supervised Representation Learning Framework for Graphs | 2021 |\n",
        "|22 | Demystifying MMD GANs | 2018 |\n",
        "|23 | Threat Model-Agnostic Adversarial Defense Using Diffusion Models | 2022 |\n",
        "|24 | On the Opportunities and Risks of Foundation Models | 2021 |\n",
        "|25 | Denoising Pretraining for Semantic Segmentation | 2022 |\n",
        "|26 | InstructPix2Pix: Learning to Follow Image Editing Instructions | 2023 |\n",
        "|27 | Language Models Are Few-Shot Learners | 2020 |\n",
        "|28 | Machine Learning for Molecular and Materials Science | 2018 |\n",
        "|29 | Learning Gradient Fields for Shape Generation | 2020 |\n",
        "|30 | A Continuous Time Framework for Discrete Denoising Models | 2022 |\n",
        "|31 | High-Frequency Space Diffusion Models for Accelerated MRI | 2022 |\n",
        "|32 | BRITS: Bidirectional Recurrent Imputation for Time Series | 2018 |\n",
        "|33 | (Certified!!) Adversarial Robustness for Free! | 2022 |\n",
        "|34 | MaskGIT: Masked Generative Image Transformer | 2022 |\n",
        "|35 | Introducing ChatGPT | 2022 |\n",
        "|36 | Your GAN Is Secretly an Energy-Based Model and You Should Use Discriminator Driven Latent Sampling | 2020 |\n",
        "|37 | Recurrent Neural Networks for Multivariate Time Series with Missing Values | 2018 |\n",
        "|38 | One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling | 2013 |\n",
        "|39 | WaveGrad: Estimating Gradients for Waveform Generation | 2020 |\n",
        "|40 | Neural Ordinary Differential Equations | 2018 |\n",
        "|41 | Likelihood Training of Schrödinger Bridge Using Forward-Backward SDEs Theory | 2021 |\n",
        "|42 | Analog Bits: Generating Discrete Data Using Diffusion Models with Self-Conditioning | 2022 |\n",
        "|43 | ComboVerse: Compositional 3D Assets Creation Using Spatially-Aware Diffusion Guidance | 2024 |\n",
        "|44 | Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images | 2020 |\n",
        "|45 | Generating Long Sequences with Sparse Transformers | 2019 |\n",
        "|46 | PaLM: Scaling Language Modeling with Pathways | 2022 |\n",
        "|47 | MR Image Denoising and Super-Resolution Using Regularized Reverse Diffusion | 2022 |\n",
        "|48 | Come-Closer-Diffuse-Faster: Accelerating Conditional Diffusion Models for Inverse Problems | 2022 |\n",
        "|49 | Score-Based Diffusion Models for Accelerated MRI | 2022 |\n",
        "|50 | Relaxing Bijectivity Constraints with Continuously Indexed Normalising Flows | 2020 |\n",
        "|51 | Generative Adversarial Networks: An Overview | 2018 |\n",
        "|52 | VQGAN-CLIP: Open Domain Image Generation and Editing with Natural Language Guidance | 2022 |\n",
        "|53 | Adaptive Diffusion Priors for Accelerated MRI Reconstruction | 2022 |\n",
        "|54 | Plug and Play Language Models: A Simple Approach to Controlled Text Generation | 2019 |\n",
        "|55 | Simulating Diffusion Bridges with Score Matching | 2021 |\n",
        "|56 | Riemannian Score-Based Generative Modeling | 2022 |\n",
        "|57 | Diffusion Schrödinger Bridge with Applications to Score-Based Generative Modeling | 2021 |\n",
        "|58 | ImageNet: A Large-Scale Hierarchical Image Database | 2009 |\n",
        "|59 | On Tracking the Partition Function | 2011 |\n",
        "|60 | Diffusion Models Beat GANs on Image Synthesis | 2021 |\n",
        "|61 | Continuous Diffusion for Categorical Data | 2022 |\n",
        "|62 | NICE: Non-Linear Independent Components Estimation | 2015 |\n",
        "|63 | Density Estimation Using Real NVP | 2016 |\n",
        "|64 | Density Estimation Using Real NVP | 2017 |\n",
        "|65 | A RAD Approach to Deep Mixture Models | 2019 |\n",
        "|66 | Score-Based Generative Modeling with Critically-Damped Langevin Diffusion | 2021 |\n",
        "|67 | GENIE: Higher-Order Denoising Diffusion Solvers | 2022 |\n",
        "|68 | Tutorial on Variational Autoencoders | 2016 |\n",
        "|69 | A Survey of Vision-Language Pre-Trained Models | 2022 |\n",
        "|70 | Implicit Generation and Generalization in Energy-Based Models | 2019 |\n",
        "|71 | Convolutional Networks on Graphs for Learning Molecular Fingerprints | 2015 |\n",
        "|72 | Time-Series Representation Learning via Temporal and Contextual Contrasting | 2021 |\n",
        "|73 | Disentangled 3D Scene Generation with Layout Learning | 2024 |\n",
        "|74 | Taming Transformers for High-Resolution Image Synthesis | 2021 |\n",
        "|75 | Reinforcement Learning for Fine-Tuning Text-to-Image Diffusion Models | 2024 |\n",
        "|76 | Testing the Manifold Hypothesis | 2016 |\n",
        "|77 | A Connection Between GANs, Inverse Reinforcement Learning, and Energy-Based Models | 2016 |\n",
        "|78 | GP-VAE: Deep Probabilistic Time Series Imputation | 2020 |\n",
        "|79 | How Much Is Enough? A Study on Diffusion Times in Score-Based Generative Models | 2022 |\n",
        "|80 | GraphDreamer: Compositional 3D Scene Synthesis from Scene Graphs | 2024 |\n",
        "|81 | Learning Generative ConvNets via Multi-Grid Modeling and Sampling | 2018 |\n",
        "|82 | Flow Contrastive Estimation of Energy-Based Models | 2020 |\n",
        "|83 | Learning Energy-Based Models by Diffusion Recovery Likelihood | 2020 |\n",
        "|84 | Remote Sensing Change Detection Using Denoising Diffusion Probabilistic Models | 2022 |\n",
        "|85 | Neural Message Passing for Quantum Chemistry | 2017 |\n",
        "|86 | Sequence-to-Sequence Text Generation with Diffusion Models | 2023 |\n",
        "|87 | Interpreting Diffusion Score Matching Using Normalizing Flow | 2021 |\n",
        "|88 | Generative Adversarial Nets | 2014 |\n",
        "|89 | A New Model for Learning in Graph Domains | 2005 |\n",
        "|90 | Variational Walkback | 2017 |\n",
        "|91 | Diffusion Models as Plug-and-Play Priors | 2022 |\n",
        "|92 | Scalable Reversible Generative Models with Free-Form Continuous Dynamics | 2019 |\n",
        "|93 | Your Classifier Is Secretly an Energy-Based Model | 2019 |\n",
        "|94 | Cutting Out the Middle-Man: Training EBMs without Sampling | 2020 |\n",
        "|95 | Generating Sequences with Recurrent Neural Networks | 2013 |\n",
        "|96 | Representations of Knowledge in Complex Systems | 1994 |\n",
        "|97 | Efficiently Modeling Long Sequences with Structured State Spaces | 2021 |\n",
        "|98 | Vector Quantized Diffusion Model for Text-to-Image Synthesis | 2022 |\n",
        "|99 | 3D Equivariant Diffusion for Target-Aware Molecule Generation | 2023 |\n",
        "|100 | A Review on Generative Adversarial Networks | 2021 |\n",
        "|101 | DeepSeek-R1: Incentivizing Reasoning Capability in LLMs | 2025 |\n",
        "|102 | World Models | 2018 |\n",
        "|103 | Inductive Representation Learning on Large Graphs | 2017 |\n",
        "|104 | Representation Learning on Graphs: Methods and Applications | 2017 |\n",
        "|105 | REPARO: Compositional 3D Assets Generation with Differentiable Layout Alignment | 2024 |\n",
        "|106 | ADBench: Anomaly Detection Benchmark | 2022 |\n",
        "|107 | SSD-LM: Semi-Autoregressive Diffusion Language Model | 2022 |\n",
        "|108 | Flexible Diffusion Modeling of Long Videos | 2022 |\n",
        "|109 | StreamingT2V: Long Video Generation from Text | 2024 |\n",
        "|110 | Learning Canonical Representations for Scene Graph to Image Generation | 2020 |\n",
        "|111 | Imagen Video: High Definition Video Generation with Diffusion Models | 2022 |\n",
        "|112 | Denoising Diffusion Probabilistic Models | 2020 |\n",
        "|113 | Cascaded Diffusion Models for High Fidelity Image Generation | 2022 |\n",
        "|114 | Classifier-Free Diffusion Guidance | 2022 |\n",
        "|115 | Video Diffusion Models | 2022 |\n",
        "|116 | Equivariant Diffusion for Molecule Generation in 3D | 2022 |\n",
        "|117 | Autoregressive Diffusion Models | 2021 |\n",
        "|118 | Argmax Flows and Multinomial Diffusion | 2021 |\n",
        "|119 | Riemannian Diffusion Models | 2022 |\n",
        "|120 | A Variational Perspective on Diffusion-Based Generative Models | 2021 |\n",
        "|121 | ProDiff: Progressive Fast Diffusion Model for Text-to-Speech | 2022 |\n",
        "|122 | Binding-Adaptive Diffusion Models for Structure-Based Drug Design | 2024 |\n",
        "|123 | Interaction-Based Retrieval-Augmented Diffusion Models for Protein-Specific Molecule Generation | 2024 |\n",
        "|124 | Protein-Ligand Interaction Prior for Binding-Aware 3D Molecule Diffusion Models | 2024 |\n",
        "|125 | Protein-Ligand Interaction Prior for Binding-Aware 3D Molecule Diffusion Models | 2024 |\n",
        "|126 | A Stochastic Estimator of the Trace of the Influence Matrix | 1989 |\n",
        "|127 | Estimation of Non-Normalized Statistical Models by Score Matching | 2005 |\n",
        "|128 | The Survey: Text Generation Models in Deep Learning | 2020 |\n",
        "|129 | Image-to-Image Translation with Conditional Adversarial Networks | 2017 |\n",
        "|130 | Mixtral of Experts | 2024 |\n",
        "|131 | Introspective Classification with Convolutional Nets | 2017 |\n"
      ],
      "metadata": {
        "id": "tR5-8AXhJU1Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References Table\n",
        "\n",
        "| # | Paper Title | Year |\n",
        "|---|------------|------|\n",
        "|132| Junction Tree Variational Autoencoder for Molecular Graph Generation | 2018 |\n",
        "|133| Subspace Diffusion Generative Models | 2022 |\n",
        "|134| Torsional Diffusion for Molecular Conformer Generation | 2022 |\n",
        "|135| Score-Based Generative Modeling of Graphs via Stochastic Differential Equations | 2022 |\n",
        "|136| Image Generation from Scene Graphs | 2018 |\n",
        "|137| Gotta Go Fast When Generating Data with Score-Based Models | 2021 |\n",
        "|138| Adversarial Score Matching and Improved Sampling for Image Generation | 2021 |\n",
        "|139| Highly Accurate Protein Structure Prediction with AlphaFold | 2021 |\n",
        "|140| Shap-E: Generating Conditional 3D Implicit Functions | 2023 |\n",
        "|141| Efficient Neural Audio Synthesis | 2018 |\n",
        "|142| Elucidating the Design Space of Diffusion-Based Generative Models | 2022 |\n",
        "|143| A Style-Based Generator Architecture for Generative Adversarial Networks | 2019 |\n",
        "|144| Denoising Diffusion Restoration Models | 2022 |\n",
        "|145| Enhancing Diffusion-Based Image Synthesis with Robust Classifier Guidance | 2022 |\n",
        "|146| Stochastic Image Denoising by Sampling from the Posterior Distribution | 2021 |\n",
        "|147| Imagic: Text-Based Real Image Editing with Diffusion Models | 2022 |\n",
        "|148| CTRL: A Conditional Transformer Language Model for Controllable Generation | 2019 |\n",
        "|149| Text2Video-Zero: Text-to-Image Diffusion Models Are Zero-Shot Video Generators | 2023 |\n",
        "|150| DiffuseMorph: Unsupervised Deformable Image Registration Using Diffusion Models | 2021 |\n",
        "|151| Maximum Likelihood Training of Implicit Nonlinear Diffusion Models | 2022 |\n",
        "|152| FLAME: Free-Form Language-Based Motion Synthesis and Editing | 2022 |\n",
        "|153| Guided-TTS 2: A Diffusion Model for High-Quality Adaptive Text-to-Speech | 2022 |\n",
        "|154| Deep Directed Generative Models with Energy-Based Probability Estimation | 2016 |\n",
        "|155| Variational Diffusion Models | 2021 |\n",
        "|156| Glow: Generative Flow with Invertible 1×1 Convolutions | 2018 |\n",
        "|157| Auto-Encoding Variational Bayes | 2013 |\n",
        "|158| An Introduction to Variational Autoencoders | 2019 |\n",
        "|159| Probabilistic Graphical Models: Principles and Techniques | 2009 |\n",
        "|160| DiffWave: A Versatile Diffusion Model for Audio Synthesis | 2020 |\n",
        "|161| GeDi: Generative Discriminator Guided Sequence Generation | 2020 |\n",
        "|162| Learning Multiple Layers of Features from Tiny Images | 2009 |\n",
        "|163| Maximum Entropy Generators for Energy-Based Models | 2019 |\n",
        "|164| The Neural Autoregressive Distribution Estimator | 2011 |\n",
        "|165| Introspective Neural Networks for Generative Modeling | 2017 |\n",
        "|166| A Tutorial on Energy-Based Learning | 2006 |\n",
        "|167| ProteinSGM: Score-Based Generative Modeling for De Novo Protein Design | 2022 |\n",
        "|168| Aligning Text-to-Image Models Using Human Feedback | 2023 |\n",
        "|169| Wasserstein Introspective Neural Networks | 2018 |\n",
        "|170| Exploring Chemical Space with Score-Based Out-of-Distribution Generation | 2022 |\n",
        "|171| Zero-Shot Voice Conditioning for Denoising Diffusion TTS Models | 2022 |\n",
        "|172| SRDiff: Single Image Super-Resolution with Diffusion Probabilistic Models | 2022 |\n",
        "|173| TextBox: A Unified Framework for Text Generation | 2021 |\n",
        "|174| Pretrained Language Models for Text Generation: A Survey | 2021 |\n",
        "|175| Enhancing the Locality of Transformers for Time Series Forecasting | 2019 |\n",
        "|176| Diffusion-LM Improves Controllable Text Generation | 2022 |\n",
        "|177| PasteGAN: A Semi-Parametric Method to Generate Images from Scene Graphs | 2019 |\n",
        "|178| LLM-Grounded Diffusion for Text-to-Image Generation | 2023 |\n",
        "|179| Magic3D: High-Resolution Text-to-3D Content Creation | 2022 |\n",
        "|180| Flow Matching for Generative Modeling | 2022 |\n",
        "|181| Retrieval-Augmented Diffusion Models for Time Series Forecasting | 2024 |\n",
        "|182| PREACHER: Paper-to-Video Agentic System | 2025 |\n",
        "|183| Pseudo Numerical Methods for Diffusion Models on Manifolds | 2021 |\n",
        "|184| Molecular Geometry Pretraining with SE(3)-Invariant Denoising | 2023 |\n",
        "|185| Flow Straight and Fast: Rectified Flow for Generative Modeling | 2022 |\n",
        "|186| Learning Diffusion Bridges on Constrained Domains | 2023 |\n",
        "|187| Let Us Build Bridges: Understanding Diffusion Generative Models | 2022 |\n",
        "|188| Neural Manifold Ordinary Differential Equations | 2020 |\n",
        "|189| Maximum Likelihood Training for Score-Based Diffusion ODEs | 2022 |\n",
        "|190| DPM-Solver: Fast ODE Solver for Diffusion Models | 2022 |\n",
        "|191| RePaint: Inpainting Using Denoising Diffusion Probabilistic Models | 2022 |\n",
        "|192| Knowledge Distillation in Iterative Generative Models | 2021 |\n",
        "|193| Understanding Diffusion Models: A Unified Perspective | 2022 |\n",
        "|194| One Transformer Can Understand Both 2D & 3D Molecular Data | 2023 |\n",
        "|195| Diffusion Probabilistic Models for 3D Point Cloud Generation | 2021 |\n",
        "|196| Score-Based Point Cloud Denoising | 2021 |\n",
        "|197| Predicting Molecular Conformation via Dynamic Graph Score Matching | 2021 |\n",
        "|198| Antigen-Specific Antibody Design with Diffusion Models | 2022 |\n",
        "|199| Multivariate Time Series Imputation with GANs | 2018 |\n",
        "|200| Conditional Point Diffusion for 3D Point Cloud Completion | 2021 |\n",
        "|201| Accelerating Diffusion Models via Early Stopping | 2022 |\n",
        "|202| Towards Deep Learning Models Resistant to Adversarial Attacks | 2018 |\n",
        "|203| Riemannian Continuous Normalizing Flows | 2020 |\n",
        "|204| Metal Inpainting in CBCT Using Score-Based Models | 2022 |\n",
        "|205| On the State of the Art of Evaluation in Neural Language Models | 2018 |\n",
        "|206| Concrete Score Matching for Discrete Data | 2022 |\n",
        "|207| On Distillation of Guided Diffusion Models | 2022 |\n",
        "|208| SDEdit: Guided Image Synthesis with SDEs | 2021 |\n",
        "|209| Improved Autoregressive Modeling with Distribution Smoothing | 2020 |\n",
        "|210| Improved Autoregressive Modeling with Distribution Smoothing | 2021 |\n",
        "|211| Estimating High-Order Gradients of the Data Distribution | 2021 |\n",
        "|212| Autoregressive Score Matching | 2020 |\n",
        "|213| Regularizing and Optimizing LSTM Language Models | 2018 |\n",
        "|214| The Monte Carlo Method | 1949 |\n",
        "|215| Learning Deep Energy Models | 2011 |\n",
        "|216| Improved Denoising Diffusion Probabilistic Models | 2021 |\n",
        "|217| GLIDE: Text-Guided Diffusion Models | 2022 |\n",
        "|218| Diffusion Models for Adversarial Purification | 2022 |\n",
        "|219| Anatomy of MCMC-Based Maximum Likelihood Learning | 2019 |\n",
        "|220| Learning Non-Convergent Short-Run MCMC for EBMs | 2019 |\n",
        "|221| Permutation Invariant Graph Generation via Score-Based Models | 2020 |\n",
        "|222| GPT-4 Technical Report | 2023 |\n",
        "|223| GPT-4 Technical Report | 2023 |\n",
        "|224| N-BEATS: Neural Basis Expansion Analysis | 2019 |\n",
        "|225| N-BEATS: Neural Basis Expansion Analysis | 2020 |\n",
        "|226| Training Language Models to Follow Instructions with Human Feedback | 2022 |\n",
        "|227| Unsupervised Medical Image Translation with Adversarial Diffusion Models | 2022 |\n",
        "|228| Normalizing Flows for Probabilistic Modeling and Inference | 2021 |\n",
        "|229| Correlation Functions and Computer Simulations | 1981 |\n",
        "|230| Neural Markov Controlled SDE | 2021 |\n",
        "|231| Scalable Diffusion Models with Transformers | 2022 |\n",
        "|232| Diffusion Model Sampling for Undersampled MR Reconstruction | 2022 |\n",
        "|233| FiLM: Visual Reasoning with a General Conditioning Layer | 2018 |\n",
        "|234| Adversarial Latent Autoencoders | 2020 |\n",
        "|235| SDXL: Improving Latent Diffusion Models | 2023 |\n",
        "|236| DreamFusion: Text-to-3D Using 2D Diffusion | 2022 |\n",
        "|237| Grad-TTS: A Diffusion Model for Text-to-Speech | 2021 |\n",
        "|238| Diffusion Autoencoders | 2022 |\n",
        "|239| FateZero: Zero-Shot Text-Based Video Editing | 2023 |\n",
        "|240| Unbiased Contrastive Divergence for Energy-Based Models | 2019 |\n",
        "|241| A Tutorial on Hidden Markov Models | 1989 |\n",
        "|242| Learning Transferable Visual Models from Natural Language | 2021 |\n",
        "|243| Improving Language Understanding by Generative Pre-Training | 2018 |\n",
        "|244| Language Models Are Unsupervised Multitask Learners | 2019 |\n",
        "|245| Hierarchical Text-Conditional Image Generation | 2022 |\n",
        "|246| Zero-Shot Text-to-Image Generation | 2021 |\n",
        "|247| Learning to Be Bayesian without Supervision | 2007 |\n",
        "|248| Least Squares Estimation without Priors | 2011 |\n",
        "|249| Autoregressive Denoising Diffusion Models for Time Series | 2021 |\n",
        "|250| Autoregressive Denoising Diffusion Models for Time Series | 2021 |\n",
        "|251| Multivariate Probabilistic Time Series Forecasting via Normalizing Flows | 2020 |\n",
        "|252| Local Nash Equilibria in Continuous Games | 2013 |\n",
        "|253| Variational Inference with Normalizing Flows | 2015 |\n",
        "|254| Stochastic Backpropagation in Deep Generative Models | 2014 |\n",
        "|255| Telescoping Density-Ratio Estimation | 2020 |\n",
        "|256| High-Dimensional Probability Estimation with Deep Density Models | 2013 |\n",
        "|257| High-Resolution Image Synthesis with Latent Diffusion Models | 2022 |\n",
        "|258| DreamBooth: Fine-Tuning Text-to-Image Diffusion Models | 2022 |\n",
        "|259| Palette: Image-to-Image Diffusion Models | 2022 |\n",
        "|260| Photorealistic Text-to-Image Diffusion Models | 2022 |\n",
        "|261| Image Super-Resolution via Iterative Refinement | 2022 |\n",
        "|262| Progressive Distillation for Fast Sampling of Diffusion Models | 2021 |\n",
        "|263| Should EBMs Model the Energy or the Score? | 2021 |\n",
        "|264| High-Dimensional Multivariate Forecasting with Gaussian Copulas | 2019 |\n",
        "|265| DeepAR: Probabilistic Forecasting with RNNs | 2020 |\n",
        "|266| Step-Unrolled Denoising Autoencoders for Text Generation | 2021 |\n",
        "|267| The Graph Neural Network Model | 2008 |\n",
        "|268| Unsupervised Anomaly Detection with GANs | 2017 |\n",
        "|269| Learning Gradient Fields for Molecular Conformation Generation | 2021 |\n",
        "|270| GraphAF: Flow-Based Autoregressive Molecular Graph Generation | 2020 |\n",
        "|271| Conditional Simulation Using Diffusion Schrödinger Bridges | 2022 |\n",
        "|272| MVDream: Multi-View Diffusion for 3D Generation | 2024 |\n",
        "|273| 3D Neural Field Generation Using Triplane Diffusion | 2023 |\n",
        "|274| Predicting In-Hospital Mortality of ICU Patients | 2012 |\n",
        "|275| Make-A-Video: Text-to-Video Generation without Text-Video Data | 2022 |\n"
      ],
      "metadata": {
        "id": "cp_SR7V0JcX4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References Table\n",
        "\n",
        "| # | Paper Title | Year |\n",
        "|---|------------|------|\n",
        "|276| The Eigenvalues of Mega-Dimensional Matrices | 1989 |\n",
        "|277| Deep Unsupervised Learning Using Nonequilibrium Thermodynamics | 2015 |\n",
        "|278| Deep Unsupervised Learning Using Nonequilibrium Thermodynamics | 2015 |\n",
        "|279| Denoising Diffusion Implicit Models | 2020 |\n",
        "|280| Applying Regularized Schrödinger-Bridge-Based Stochastic Process in Generative Modeling | 2022 |\n",
        "|281| Maximum Likelihood Training of Score-Based Diffusion Models | 2021 |\n",
        "|282| Generative Modeling by Estimating Gradients of the Data Distribution | 2019 |\n",
        "|283| Improved Techniques for Training Score-Based Generative Models | 2020 |\n",
        "|284| Sliced Score Matching: A Scalable Approach to Density and Score Estimation | 2019 |\n",
        "|285| How to Train Your Energy-Based Models | 2021 |\n",
        "|286| Solving Inverse Problems in Medical Imaging with Score-Based Generative Models | 2021 |\n",
        "|287| Score-Based Generative Modeling through Stochastic Differential Equations | 2020 |\n",
        "|288| Stochastic Optimization | 2012 |\n",
        "|289| PointDP: Diffusion-Driven Purification against Adversarial Attacks on 3D Point Clouds | 2022 |\n",
        "|290| EdiTTS: Score-Based Editing for Controllable Text-to-Speech | 2021 |\n",
        "|291| A Tensor-Based Method for Missing Traffic Data Completion | 2013 |\n",
        "|292| Make-it-3D: High-Fidelity 3D Creation from a Single Image with Diffusion Prior | 2023 |\n",
        "|293| CSDI: Conditional Score-Based Diffusion Models for Probabilistic Time Series Imputation | 2021 |\n",
        "|294| Human Motion Diffusion Model | 2022 |\n",
        "|295| Bootstrapped Representation Learning on Graphs | 2021 |\n",
        "|296| A Note on the Evaluation of Generative Models | 2015 |\n",
        "|297| VideoTetris: Towards Compositional Text-to-Video Generation | 2024 |\n",
        "|298| LLaMA: Open and Efficient Foundation Language Models | 2023 |\n",
        "|299| Effective Data Augmentation with Diffusion Models | 2023 |\n",
        "|300| Diffusion Probabilistic Modeling of Protein Backbones in 3D | 2023 |\n",
        "|301| Score-Based Generative Modeling in Latent Space | 2021 |\n",
        "|302| UniTune: Text-Driven Image Editing by Fine-Tuning on a Single Image | 2022 |\n",
        "|303| WaveNet: A Generative Model for Raw Audio | 2016 |\n",
        "|304| Pixel Recurrent Neural Networks | 2016 |\n",
        "|305| CG3D: Compositional Generation for Text-to-3D via Gaussian Splatting | 2023 |\n",
        "|306| A Connection between Score Matching and Denoising Autoencoders | 2011 |\n",
        "|307| Extracting and Composing Robust Features with Denoising Autoencoders | 2008 |\n",
        "|308| Diffusion Model Alignment Using Direct Preference Optimization | 2024 |\n",
        "|309| Rectified Diffusion: Straightness Is Not Your Need in Rectified Flow | 2024 |\n",
        "|310| Guided Diffusion Model for Adversarial Purification | 2022 |\n",
        "|311| Revolutionizing Reinforcement Learning Framework for Diffusion LLMs | 2025 |\n",
        "|312| Co-Evolving LLM Coder and Unit Tester via Reinforcement Learning | 2025 |\n",
        "|313| KnowDA: Knowledge Mixture Model for Data Augmentation in Few-Shot NLP | 2022 |\n",
        "|314| ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation | 2023 |\n",
        "|315| Diffusion-GAN: Training GANs with Diffusion | 2022 |\n",
        "|316| Learning Fast Samplers for Diffusion Models | 2021 |\n",
        "|317| Learning to Efficiently Sample from Diffusion Probabilistic Models | 2021 |\n",
        "|318| Emergent Abilities of Large Language Models | 2022 |\n",
        "|319| Deblurring via Stochastic Refinement | 2022 |\n",
        "|320| Visual ChatGPT: Talking, Drawing, and Editing with Visual Foundation Models | 2023 |\n",
        "|321| Stochastic Normalizing Flows | 2020 |\n",
        "|322| Tune-A-Video: One-Shot Tuning for Text-to-Video Generation | 2022 |\n",
        "|323| Guided Diffusion Model for Adversarial Purification from Random Noise | 2022 |\n",
        "|324| ItôTTS and ItôWave: Linear SDEs for Audio Generation | 2021 |\n",
        "|325| Graph Neural Networks in Recommender Systems: A Survey | 2020 |\n",
        "|326| A Comprehensive Survey on Graph Neural Networks | 2020 |\n",
        "|327| AnoDDPM: Anomaly Detection with Denoising Diffusion Probabilistic Models | 2022 |\n",
        "|328| Tackling the Generative Learning Trilemma with Diffusion GANs | 2021 |\n",
        "|329| A Theory of Generative ConvNet | 2016 |\n",
        "|330| Vector Quantized Diffusion Model with CodeUNet for Text-to-Sign Generation | 2022 |\n",
        "|331| Crystal Diffusion Variational Autoencoder for Periodic Material Generation | 2021 |\n",
        "|332| Measurement-Conditioned DDPM for Medical Image Reconstruction | 2022 |\n",
        "|333| Open-Vocabulary Panoptic Segmentation with Diffusion Models | 2023 |\n",
        "|334| ImageReward: Learning Human Preferences for Text-to-Image Generation | 2024 |\n",
        "|335| Dream3D: Zero-Shot Text-to-3D Synthesis | 2022 |\n",
        "|336| Self-Supervised Graph-Level Representation Learning | 2021 |\n",
        "|337| GeoDiff: A Geometric Diffusion Model for Molecular Conformation | 2021 |\n",
        "|338| Versatile Diffusion: Text, Images, and Variations | 2022 |\n",
        "|339| ScoreGrad: Multivariate Time Series Forecasting with EBMs | 2021 |\n",
        "|340| DiffSound: Discrete Diffusion Model for Text-to-Sound Generation | 2022 |\n",
        "|341| Visual Anomaly Detection for Images: A Survey | 2021 |\n",
        "|342| FUDGE: Controlled Text Generation with Future Discriminators | 2021 |\n",
        "|343| Fine-Tuning Diffusion Models with Human Feedback | 2024 |\n",
        "|344| Omni-Granular Ego-Semantic Propagation for Graph Learning | 2022 |\n",
        "|345| Unsupervised Time-Series Representation Learning with Bilinear Fusion | 2022 |\n",
        "|346| Diffusion-Based Scene Graph to Image Generation | 2022 |\n",
        "|347| Graphusion: Latent Diffusion for Graph Generation | 2024 |\n",
        "|348| DPGN: Distribution Propagation Graph Network | 2020 |\n",
        "|349| Improving Diffusion-Based Image Synthesis with Context Prediction | 2023 |\n",
        "|350| Structure-Guided Adversarial Training of Diffusion Models | 2024 |\n",
        "|351| MMADA: Multimodal Large Diffusion Language Models | 2025 |\n",
        "|352| ReasonFlux: Hierarchical LLM Reasoning via Thought Templates | 2025 |\n",
        "|353| Mastering Text-to-Image Diffusion with Multimodal LLMs | 2024 |\n",
        "|354| Buffer of Thoughts: Thought-Augmented Reasoning with LLMs | 2024 |\n",
        "|355| EditWorld: Simulating World Dynamics for Image Editing | 2024 |\n",
        "|356| Semantic Score Distillation Sampling for Text-to-3D Generation | 2024 |\n",
        "|357| Cross-Modal Contextualized Diffusion Models | 2024 |\n",
        "|358| Score-Based Graph Generative Modeling with Self-Guided Latent Diffusion | 2023 |\n",
        "|359| Consistency Flow Matching | 2024 |\n",
        "|360| Lossy Image Compression with Conditional Diffusion Models | 2022 |\n",
        "|361| Diffusion Probabilistic Modeling for Video Generation | 2022 |\n",
        "|362| ST-MVL: Filling Missing Values in Geo-Sensory Time Series | 2016 |\n",
        "|363| Adversarial Purification with Score-Based Generative Models | 2021 |\n",
        "|364| Time-Series Generative Adversarial Networks | 2019 |\n",
        "|365| Diffusion Models and Semi-Supervised Learning with Few Labels | 2023 |\n",
        "|366| CoCa: Contrastive Captioners as Image-Text Foundation Models | 2022 |\n",
        "|367| Latent Diffusion Energy-Based Model for Text Modeling | 2022 |\n",
        "|368| Generating Videos with Dynamics-Aware GANs | 2022 |\n",
        "|369| Florence: A New Foundation Model for Computer Vision | 2021 |\n",
        "|370| Pre-Training via Denoising for Molecular Property Prediction | 2023 |\n",
        "|371| IPDreamer: Appearance-Controlled 3D Object Generation | 2023 |\n",
        "|372| Trans4D: Geometry-Aware Text-to-4D Synthesis | 2024 |\n",
        "|373| LION: Latent Point Diffusion Models for 3D Shape Generation | 2022 |\n",
        "|374| Adding Conditional Control to Text-to-Image Diffusion Models | 2023 |\n",
        "|375| MotionDiffuse: Text-Driven Human Motion Generation | 2022 |\n",
        "|376| Diffusion Normalizing Flow | 2021 |\n",
        "|377| Fast Sampling of Diffusion Models with Exponential Integrator | 2022 |\n",
        "|378| gDDIM: Generalized Denoising Diffusion Implicit Models | 2022 |\n",
        "|379| OPT: Open Pre-Trained Transformer Language Models | 2022 |\n",
        "|380| Cross Reconstruction Transformer for Time Series Learning | 2022 |\n",
        "|381| RealCompo: Balancing Realism and Compositionality in Diffusion Models | 2024 |\n",
        "|382| IterComp: Iterative Composition-Aware Feedback Learning | 2024 |\n",
        "|383| Multimodal Chain-of-Thought Reasoning in Language Models | 2023 |\n",
        "|384| Energy-Based Generative Adversarial Network | 2016 |\n",
        "|385| EGSDE: Unpaired Image-to-Image Translation via Energy-Guided SDEs | 2022 |\n",
        "|386| PyOD: A Python Toolbox for Scalable Outlier Detection | 2019 |\n",
        "|387| Truncated Diffusion Probabilistic Models | 2022 |\n",
        "|388| Uni-Mol: Universal 3D Molecular Representation Learning | 2023 |\n",
        "|389| Graph Neural Networks: A Review of Methods and Applications | 2020 |\n",
        "|390| 3D Shape Generation via Point-Voxel Diffusion | 2021 |\n",
        "|391| Distribution-Aware Data Expansion with Diffusion Models | 2024 |\n",
        "|392| Discrete Contrastive Diffusion for Cross-Modal Generation | 2022 |\n",
        "|393| Deep Graph Contrastive Representation Learning | 2020 |\n",
        "|394| Vlogger: Make Your Dream a Vlog | 2024 |\n",
        "|395| Score-Based Generative Classifiers | 2021 |\n",
        "|396| ReasonFlux-PRM: Trajectory-Aware PRMs for Long CoT Reasoning | 2025 |\n"
      ],
      "metadata": {
        "id": "jTlCxK3OJimm"
      }
    }
  ]
}