{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![profile.jpg](data:image/jpeg;base64,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)\n",
        "\n",
        "# Yang Song (宋飏)"
      ],
      "metadata": {
        "id": "A56N_oBolVG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Diffusion Models: A Comprehensive Survey of Methods and Applications\n",
        "\n",
        "#https://arxiv.org/pdf/2209.00796\n",
        "\n",
        "## Abstract\n",
        "\n",
        "This paper presents a comprehensive survey of diffusion models, a class of probabilistic generative models that have recently achieved state-of-the-art performance across many domains, including image synthesis, video generation, natural language generation, and scientific applications. The survey unifies different diffusion formulations—denoising diffusion probabilistic models (DDPMs), score-based generative models (SGMs), and stochastic differential equation (SDE)–based models—under a common theoretical framework. It systematically categorizes recent advances in efficient sampling, likelihood estimation, handling structured data, and connections to other generative paradigms, while also outlining applications and future research directions.\n",
        "\n",
        "---\n",
        "\n",
        "## Problems\n",
        "\n",
        "The paper identifies several key challenges in diffusion modeling research:\n",
        "\n",
        "- High computational cost due to iterative and slow sampling procedures.\n",
        "- Suboptimal or loose likelihood bounds arising from variational training objectives.\n",
        "- Difficulty in modeling data with special structures such as discrete spaces, manifolds, or invariances.\n",
        "- Fragmentation of the literature, making it difficult for researchers to understand overarching trends and theoretical connections.\n",
        "- Limited theoretical understanding of diffusion dynamics, reversibility, and optimization trade-offs.\n",
        "\n",
        "These issues hinder both scalability and broader adoption of diffusion models.\n",
        "\n",
        "---\n",
        "\n",
        "## Proposed Solutions\n",
        "\n",
        "The survey organizes proposed solutions into three major research directions:\n",
        "\n",
        "1. **Efficient sampling techniques**, including:\n",
        "   - Learning-free methods such as SDE solvers and ODE solvers.\n",
        "   - Learning-based methods such as optimized discretization, truncation, and knowledge distillation.\n",
        "\n",
        "2. **Improved likelihood estimation**, achieved through:\n",
        "   - Optimized noise schedules.\n",
        "   - Reverse variance learning.\n",
        "   - Exact likelihood computation using SDE and probability flow ODE formulations.\n",
        "\n",
        "3. **Extensions to structured data**, enabling diffusion models to handle:\n",
        "   - Discrete data.\n",
        "   - Invariant data.\n",
        "   - Manifold-constrained data.\n",
        "\n",
        "Additionally, the paper highlights hybrid approaches that combine diffusion models with VAEs, GANs, normalizing flows, autoregressive models, and energy-based models.\n",
        "\n",
        "---\n",
        "\n",
        "## Purpose\n",
        "\n",
        "The primary purpose of the paper is to provide a unified, structured overview of diffusion models that serves both as an entry point for new researchers and as a reference for experienced practitioners. The authors aim to clarify conceptual connections between different diffusion formulations, summarize methodological advances, and identify promising directions for future research.\n",
        "\n",
        "---\n",
        "\n",
        "## Methodology\n",
        "\n",
        "The authors conduct a systematic literature survey covering foundational theory, algorithmic developments, and applications. Specifically, they:\n",
        "\n",
        "- Formally derive and compare DDPMs, SGMs, and score-based SDE formulations.\n",
        "- Analyze sampling and training objectives through probabilistic, variational, and stochastic calculus perspectives.\n",
        "- Classify methods using a detailed taxonomy spanning algorithms, theoretical improvements, and application domains.\n",
        "- Review empirical results from a wide range of published works without proposing a new model.\n",
        "\n",
        "The methodology is analytical and comparative rather than experimental.\n",
        "\n",
        "---\n",
        "\n",
        "## Results\n",
        "\n",
        "The survey demonstrates that:\n",
        "\n",
        "- Diffusion models unify discrete-time Markov chains and continuous-time SDE/ODE formulations.\n",
        "- Efficient samplers can reduce generation steps from hundreds to tens while preserving sample quality.\n",
        "- Likelihood estimation can be improved or made exact under certain formulations, especially via score-based SDEs and probability flow ODEs.\n",
        "- Diffusion models are highly flexible and can be adapted to images, text, audio, video, graphs, time series, and scientific data.\n",
        "- Diffusion models now rival or surpass GANs and VAEs in both quality and stability across many tasks.\n",
        "\n",
        "These findings establish diffusion models as a dominant generative modeling paradigm.\n",
        "\n",
        "---\n",
        "\n",
        "## Conclusions\n",
        "\n",
        "The paper concludes that diffusion models represent a unifying and powerful framework for generative modeling, grounded in probabilistic diffusion and stochastic processes. While they achieve exceptional performance, key open problems remain in theoretical understanding, sampling efficiency, and representation learning. The authors emphasize future directions such as diffusion foundation models, deeper theoretical analysis, latent diffusion, and integration with large language models and multimodal systems.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "0Wop37fdlGAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Structured Review Table: Problems, Limitations, and Proposed Solutions in Diffusion Models\n",
        "\n",
        "| **Key Problem / Research Gap** | **How It Limits Prior Work** | **How the Paper (Surveyed Methods) Addresses It** |\n",
        "|---|---|---|\n",
        "| Slow and computationally expensive sampling | Early diffusion models require hundreds or thousands of denoising steps, making them impractical for real-time or large-scale deployment | Reviews efficient sampling strategies including improved discretization, higher-order numerical solvers, probability flow ODEs, and distillation-based acceleration methods |\n",
        "| Loose or suboptimal likelihood bounds | Variational training objectives provide weak approximations of true data likelihood, limiting principled model comparison and evaluation | Surveys improved likelihood formulations using score-based SDEs, optimized noise schedules, and exact likelihood computation via probability flow ODEs |\n",
        "| Fragmented theoretical formulations | Discrete-time DDPMs, continuous-time score-based models, and SDE approaches were historically treated as separate frameworks | Unifies these approaches under a common stochastic process framework, showing equivalence and connections through SDE and ODE formulations |\n",
        "| Limited handling of structured data | Standard diffusion models assume continuous Euclidean data, limiting applicability to discrete, manifold, or invariant data types | Reviews extensions of diffusion models to discrete spaces, manifolds, graphs, and invariant data via tailored noise processes and constrained dynamics |\n",
        "| Poor interpretability of diffusion dynamics | Prior work often treated diffusion models as black-box generative systems with limited theoretical insight | Provides probabilistic and physical interpretations of diffusion processes using stochastic calculus, thermodynamics, and score matching theory |\n",
        "| Training inefficiency and instability | Large computational cost and sensitivity to hyperparameters hinder scalability and reproducibility | Surveys improved training practices including noise conditioning, variance learning, exponential moving average (EMA) stabilization, and architectural refinements |\n",
        "| Limited comparison with other generative paradigms | Earlier studies often compared diffusion models narrowly against GANs or VAEs without a unified perspective | Positions diffusion models within the broader generative modeling landscape, clarifying relationships to VAEs, GANs, normalizing flows, and energy-based models |\n",
        "| Unclear future research directions | Rapid progress makes it difficult to identify open problems and long-term challenges | Explicitly outlines future directions such as diffusion foundation models, multimodal diffusion, theoretical convergence analysis, and large-scale deployment |\n",
        "\n",
        "---\n",
        "\n",
        "## Summary Insight\n",
        "\n",
        "The survey does not propose a single new algorithm. Instead, its core contribution lies in systematizing the diffusion literature, clarifying theoretical equivalences, and identifying methodological solutions that collectively overcome the main limitations of early diffusion models. This consolidation is critical for advancing diffusion models from high-performing prototypes to scalable, general-purpose generative systems.\n"
      ],
      "metadata": {
        "id": "rhTz4fYVmP9u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Related Work Extracted from References\n",
        "\n",
        "| **Author(s)** | **Year** | **Title** | **Venue** | **Connection to This Paper** |\n",
        "|---|---|---|---|---|\n",
        "| Sohl-Dickstein et al. | 2015 | *Deep Unsupervised Learning using Nonequilibrium Thermodynamics* | ICML | Introduced the foundational idea of modeling data generation as a diffusion process and learning its reversal, forming the conceptual basis of modern diffusion models. |\n",
        "| Ho, Jain, Abbeel | 2020 | *Denoising Diffusion Probabilistic Models* | NeurIPS | Established the modern DDPM framework using variational inference and discrete-time Gaussian diffusion, which the survey generalizes and unifies. |\n",
        "| Song & Ermon | 2019 | *Generative Modeling by Estimating Gradients of the Data Distribution* | NeurIPS | Introduced score-matching–based generative modeling, which later became central to score-based diffusion and SDE formulations reviewed in the paper. |\n",
        "| Song et al. | 2021 | *Score-Based Generative Modeling through Stochastic Differential Equations* | ICLR | Unified score-based models and diffusion probabilistic models under continuous-time SDEs, a key theoretical framework emphasized in the survey. |\n",
        "| Anderson | 1982 | *Reverse-Time Diffusion Equation Models* | Stochastic Processes and Their Applications | Provided the mathematical foundation for reverse-time diffusion, underpinning theoretical formulations of reverse diffusion processes. |\n",
        "| Vincent | 2011 | *A Connection Between Score Matching and Denoising Autoencoders* | Neural Computation | Established the theoretical link between denoising and score estimation, directly motivating denoising-based diffusion training objectives. |\n",
        "| Hyvärinen | 2005 | *Estimation of Non-Normalized Statistical Models by Score Matching* | Journal of Machine Learning Research | Introduced score matching as a method for learning unnormalized models, forming the theoretical backbone of score-based diffusion models. |\n",
        "| Neal | 2011 | *MCMC Using Hamiltonian Dynamics* | Handbook of MCMC | Provided theoretical grounding for Langevin and stochastic sampling methods closely related to diffusion model sampling dynamics. |\n",
        "| Goodfellow et al. | 2014 | *Generative Adversarial Nets* | NeurIPS | Served as the dominant generative paradigm prior to diffusion models and is used as a key comparison baseline throughout the survey. |\n",
        "| Kingma & Welling | 2014 | *Auto-Encoding Variational Bayes* | ICLR | Introduced VAEs, whose variational framework and latent variable interpretation are compared and connected to diffusion models in the survey. |\n",
        "| Dinh et al. | 2017 | *Density Estimation using Real NVP* | ICLR | Represented normalizing flows, another likelihood-based generative framework contrasted with diffusion models. |\n",
        "| Bengio et al. | 2013 | *Generalized Denoising Auto-Encoders as Generative Models* | NeurIPS | Early work linking denoising and generative modeling, conceptually preceding diffusion-based denoising formulations. |\n",
        "| Welling & Teh | 2011 | *Bayesian Learning via Stochastic Gradient Langevin Dynamics* | ICML | Introduced stochastic gradient Langevin dynamics, influencing diffusion-based sampling and annealed Langevin dynamics discussed in the survey. |\n",
        "\n",
        "---\n",
        "\n",
        "## Key Scholarly Role of These Works\n",
        "\n",
        "Together, these references:\n",
        "\n",
        "- Establish the physical, probabilistic, and thermodynamic foundations of diffusion modeling.\n",
        "- Motivate the transition from energy-based and score-matching models to modern diffusion models.\n",
        "- Provide the theoretical basis for sampling methods, including Langevin dynamics, reverse-time diffusion, and stochastic differential equations.\n",
        "- Situate diffusion models within the broader generative modeling landscape relative to GANs, VAEs, and normalizing flows.\n",
        "\n",
        "The survey’s primary contribution lies in unifying these threads into a single theoretical and algorithmic framework, rather than introducing a new generative model.\n"
      ],
      "metadata": {
        "id": "fp1mvQbpnKVP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mathematical Foundations of Diffusion Models (Unified View)\n",
        "\n",
        "## 1. Probabilistic Foundations\n",
        "\n",
        "### Data Distribution\n",
        "\n",
        "**Notation**\n",
        "$$\n",
        "x_0 \\sim q(x_0)\n",
        "$$\n",
        "\n",
        "**Meaning**  \n",
        "Real data is assumed to come from an unknown probability distribution.\n",
        "\n",
        "**Role**  \n",
        "The goal of diffusion models is to learn how to sample from this distribution.\n",
        "\n",
        "---\n",
        "\n",
        "### Joint and Conditional Distributions\n",
        "\n",
        "**Equation**\n",
        "$$\n",
        "q(x_1,\\ldots,x_T \\mid x_0) = \\prod_{t=1}^{T} q(x_t \\mid x_{t-1})\n",
        "$$\n",
        "\n",
        "**Meaning**  \n",
        "The diffusion process is a Markov chain.\n",
        "\n",
        "**Role**  \n",
        "Enables tractable modeling of progressive noise injection.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Forward Diffusion Process (Noise Injection)\n",
        "\n",
        "### Gaussian Transition Kernel\n",
        "\n",
        "**Equation**\n",
        "$$\n",
        "q(x_t \\mid x_{t-1}) = \\mathcal{N}\\!\\left(\\sqrt{1-\\beta_t}\\,x_{t-1}, \\beta_t I\\right)\n",
        "$$\n",
        "\n",
        "**Meaning**  \n",
        "At each step, Gaussian noise is added.\n",
        "\n",
        "**Role**  \n",
        "Guarantees convergence to a Gaussian distribution.\n",
        "\n",
        "---\n",
        "\n",
        "### Closed-Form Marginal Distribution\n",
        "\n",
        "**Equation**\n",
        "$$\n",
        "q(x_t \\mid x_0) = \\mathcal{N}\\!\\left(\\sqrt{\\bar{\\alpha}_t}\\,x_0, (1-\\bar{\\alpha}_t)I\\right)\n",
        "$$\n",
        "\n",
        "**Meaning**  \n",
        "Any noisy state can be sampled directly.\n",
        "\n",
        "**Role**  \n",
        "Enables efficient training and reparameterization.\n",
        "\n",
        "---\n",
        "\n",
        "### Reparameterization Trick\n",
        "\n",
        "**Equation**\n",
        "$$\n",
        "x_t = \\sqrt{\\bar{\\alpha}_t}\\,x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\,\\epsilon,\n",
        "\\qquad \\epsilon \\sim \\mathcal{N}(0,I)\n",
        "$$\n",
        "\n",
        "**Meaning**  \n",
        "Noise is injected via a standard Gaussian variable.\n",
        "\n",
        "**Role**  \n",
        "Allows gradient-based optimization.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Reverse Diffusion (Generation)\n",
        "\n",
        "### Reverse Markov Kernel\n",
        "\n",
        "**Equation**\n",
        "$$\n",
        "p_\\theta(x_{t-1} \\mid x_t)\n",
        "= \\mathcal{N}\\!\\left(\\mu_\\theta(x_t,t), \\Sigma_\\theta(x_t,t)\\right)\n",
        "$$\n",
        "\n",
        "**Meaning**  \n",
        "The model learns how to denoise step by step.\n",
        "\n",
        "**Role**  \n",
        "Core generative mechanism.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Variational Inference and Likelihood\n",
        "\n",
        "### KL Divergence Objective\n",
        "\n",
        "**Equation**\n",
        "$$\n",
        "D_{\\mathrm{KL}}\\!\\left(q \\,\\|\\, p_\\theta\\right)\n",
        "$$\n",
        "\n",
        "**Meaning**  \n",
        "Measures mismatch between true and learned processes.\n",
        "\n",
        "**Role**  \n",
        "Training objective for diffusion models.\n",
        "\n",
        "---\n",
        "\n",
        "### Variational Lower Bound (VLB)\n",
        "\n",
        "**Equation**\n",
        "$$\n",
        "\\log p_\\theta(x_0) \\ge \\mathcal{L}_{\\mathrm{VLB}}\n",
        "$$\n",
        "\n",
        "**Meaning**  \n",
        "A tractable lower bound on likelihood.\n",
        "\n",
        "**Role**  \n",
        "Enables training when likelihood is intractable.\n",
        "\n",
        "---\n",
        "\n",
        "### Monte Carlo Estimation\n",
        "\n",
        "**Meaning**  \n",
        "Expectations are approximated using samples.\n",
        "\n",
        "**Role**  \n",
        "Makes training scalable.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Score-Based Modeling\n",
        "\n",
        "### Score Function\n",
        "\n",
        "**Definition**\n",
        "$$\n",
        "\\nabla_x \\log p(x)\n",
        "$$\n",
        "\n",
        "**Meaning**  \n",
        "Direction of maximum density increase.\n",
        "\n",
        "**Role**  \n",
        "Central object learned instead of probability density.\n",
        "\n",
        "---\n",
        "\n",
        "### Denoising Score Matching\n",
        "\n",
        "**Loss**\n",
        "$$\n",
        "\\mathbb{E}\\big[\\|\\epsilon + \\sigma_t s_\\theta(x_t,t)\\|^2\\big]\n",
        "$$\n",
        "\n",
        "**Meaning**  \n",
        "Learns the score by predicting noise.\n",
        "\n",
        "**Role**  \n",
        "Equivalent to DDPM training.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Langevin Dynamics (Sampling)\n",
        "\n",
        "### Langevin Update Rule\n",
        "\n",
        "**Equation**\n",
        "$$\n",
        "x_{k+1} = x_k + \\frac{\\eta}{2}\\nabla \\log p(x_k) + \\sqrt{\\eta}\\,\\epsilon\n",
        "$$\n",
        "\n",
        "**Meaning**  \n",
        "Gradient ascent plus noise.\n",
        "\n",
        "**Role**  \n",
        "Sampling method for score-based models.\n",
        "\n",
        "---\n",
        "\n",
        "### Annealed Langevin Dynamics\n",
        "\n",
        "**Meaning**  \n",
        "Noise scale is gradually reduced.\n",
        "\n",
        "**Role**  \n",
        "Improves convergence during sampling.\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Continuous-Time Formulation\n",
        "\n",
        "### Stochastic Differential Equation (SDE)\n",
        "\n",
        "**Equation**\n",
        "$$\n",
        "dx = f(x,t)\\,dt + g(t)\\,dw\n",
        "$$\n",
        "\n",
        "**Meaning**  \n",
        "Continuous diffusion process.\n",
        "\n",
        "**Role**  \n",
        "Unifies DDPMs and score-based models.\n",
        "\n",
        "---\n",
        "\n",
        "### Wiener Process\n",
        "\n",
        "**Meaning**  \n",
        "Mathematical model of Brownian motion.\n",
        "\n",
        "**Role**  \n",
        "Source of randomness in diffusion.\n",
        "\n",
        "---\n",
        "\n",
        "### Reverse-Time SDE\n",
        "\n",
        "**Equation**\n",
        "$$\n",
        "dx = \\big[f(x,t) - g(t)^2 \\nabla_x \\log q_t(x)\\big]dt + g(t)\\,d\\bar{w}\n",
        "$$\n",
        "\n",
        "**Meaning**  \n",
        "Noise is removed using score estimates.\n",
        "\n",
        "**Role**  \n",
        "Theoretical foundation of generation.\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Probability Flow ODE\n",
        "\n",
        "### Deterministic ODE\n",
        "\n",
        "**Equation**\n",
        "$$\n",
        "dx = \\big[f(x,t) - \\tfrac{1}{2}g(t)^2 \\nabla_x \\log q_t(x)\\big]dt\n",
        "$$\n",
        "\n",
        "**Meaning**  \n",
        "Same marginals as SDE, no randomness.\n",
        "\n",
        "**Role**  \n",
        "Enables fast, deterministic sampling.\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Numerical Analysis\n",
        "\n",
        "### SDE Solvers\n",
        "\n",
        "**Examples**  \n",
        "Euler–Maruyama, Predictor–Corrector\n",
        "\n",
        "**Role**  \n",
        "Approximate reverse diffusion paths.\n",
        "\n",
        "---\n",
        "\n",
        "### ODE Solvers\n",
        "\n",
        "**Examples**  \n",
        "Euler, Heun, Runge–Kutta, exponential integrators\n",
        "\n",
        "**Role**  \n",
        "Dramatically accelerate sampling.\n",
        "\n",
        "---\n",
        "\n",
        "## 10. Exact Likelihood Computation\n",
        "\n",
        "### Change of Variables Formula\n",
        "\n",
        "**Equation**\n",
        "$$\n",
        "\\log p(x_0) = \\log p(x_T) + \\int \\nabla \\cdot f(x_t,t)\\,dt\n",
        "$$\n",
        "\n",
        "**Meaning**  \n",
        "Continuous normalizing flow.\n",
        "\n",
        "**Role**  \n",
        "Enables exact likelihood evaluation (computationally expensive).\n",
        "\n",
        "---\n",
        "\n",
        "### Hutchinson Trace Estimator\n",
        "\n",
        "**Meaning**  \n",
        "Efficient divergence estimation.\n",
        "\n",
        "**Role**  \n",
        "Makes likelihood computation feasible.\n",
        "\n",
        "---\n",
        "\n",
        "## 11. Information-Theoretic Concepts\n",
        "\n",
        "### Entropy\n",
        "\n",
        "**Meaning**  \n",
        "Measure of uncertainty.\n",
        "\n",
        "**Role**  \n",
        "Forward diffusion increases entropy.\n",
        "\n",
        "---\n",
        "\n",
        "### Maximum Entropy Principle\n",
        "\n",
        "**Meaning**  \n",
        "Gaussian distributions maximize entropy under a variance constraint.\n",
        "\n",
        "**Role**  \n",
        "Explains Gaussian convergence.\n",
        "\n",
        "---\n",
        "\n",
        "## 12. Discrete Mathematics Extensions\n",
        "\n",
        "### Markov Chains on Discrete Spaces\n",
        "\n",
        "**Equation**\n",
        "$$\n",
        "q(x_t \\mid x_{t-1}) = v(x_t)^\\top Q_t v(x_{t-1})\n",
        "$$\n",
        "\n",
        "**Meaning**  \n",
        "Random walks instead of Gaussian noise.\n",
        "\n",
        "**Role**  \n",
        "Enables diffusion on text, tokens, and graphs.\n",
        "\n",
        "---\n",
        "\n",
        "## 13. High-Order Statistics\n",
        "\n",
        "### Higher-Order Score Matching\n",
        "\n",
        "**Meaning**  \n",
        "Uses Hessians and higher-order derivatives.\n",
        "\n",
        "**Role**  \n",
        "Improves likelihood estimation and sampling accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "## 14. Optimization Theory\n",
        "\n",
        "### Stochastic Gradient Descent\n",
        "\n",
        "**Role**  \n",
        "Optimizes neural score networks.\n",
        "\n",
        "---\n",
        "\n",
        "### Dynamic Programming\n",
        "\n",
        "**Role**  \n",
        "Optimizes discretization schedules.\n",
        "\n",
        "---\n",
        "\n",
        "## Summary Insight (Mathematical Core)\n",
        "\n",
        "The paper shows that diffusion models are fundamentally:\n",
        "\n",
        "- Stochastic processes governed by SDEs  \n",
        "- Bayesian generative models  \n",
        "- Score-matching systems  \n",
        "- Thermodynamic entropy-increasing processes  \n",
        "- Continuous normalizing flows  \n",
        "\n",
        "All major diffusion variants differ only in discretization, parameterization, and numerical solvers, not in underlying mathematical principles.\n"
      ],
      "metadata": {
        "id": "b_94Vz08nxrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Taxonomy of Diffusion Model Variants (Figure 1 Summary)\n",
        "\n",
        "Figure 1 organizes the diffusion modeling literature into four major axes, reflecting both methodological development and application breadth.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Algorithmic Variants of Diffusion Models\n",
        "\n",
        "This axis categorizes diffusion models based on how the core diffusion process is improved or adapted.\n",
        "\n",
        "### 1.1 Diffusion Models with Efficient Sampling\n",
        "\n",
        "**Focus**  \n",
        "Reducing the high computational cost of iterative denoising.\n",
        "\n",
        "**Learning-Free Sampling**\n",
        "- SDE solvers based on discretized reverse-time stochastic differential equations\n",
        "- ODE solvers based on deterministic probability flow ODEs\n",
        "\n",
        "**Learning-Based Sampling**\n",
        "- Optimized discretization through learning optimal time steps\n",
        "- Truncated diffusion by shortening diffusion trajectories\n",
        "- Knowledge distillation by training faster student samplers\n",
        "\n",
        "---\n",
        "\n",
        "### 1.2 Diffusion Models with Improved Likelihood\n",
        "\n",
        "**Focus**  \n",
        "Tightening likelihood bounds and improving density estimation.\n",
        "\n",
        "- Noise schedule optimization through learned or designed forward noise schedules\n",
        "- Reverse variance learning by modeling the variance of reverse transitions\n",
        "- Exact likelihood computation using probability flow ODEs and score-based SDE theory\n",
        "\n",
        "---\n",
        "\n",
        "### 1.3 Diffusion Models for Data with Special Structures\n",
        "\n",
        "**Focus**  \n",
        "Extending diffusion models beyond standard continuous Euclidean data.\n",
        "\n",
        "- Discrete data diffusion over categorical or symbolic spaces\n",
        "- Data with invariant structures such as permutation, rotation, or symmetry constraints\n",
        "- Data with manifold structures:\n",
        "  - Known manifolds such as spheres or rotation groups\n",
        "  - Learned manifolds through latent diffusion spaces\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Connections with Other Generative Models\n",
        "\n",
        "This axis situates diffusion models within the broader generative modeling ecosystem.\n",
        "\n",
        "- Diffusion language models\n",
        "- Variational autoencoders\n",
        "- Generative adversarial networks\n",
        "- Normalizing flows\n",
        "- Autoregressive models\n",
        "- Energy-based models\n",
        "\n",
        "These connections reveal diffusion models as a unifying framework bridging likelihood-based and implicit generative modeling paradigms.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Applications of Diffusion Models\n",
        "\n",
        "This axis classifies where diffusion models are applied.\n",
        "\n",
        "### 3.1 Core Generation Modes\n",
        "\n",
        "- Unconditional diffusion\n",
        "- Conditional diffusion using labels, classifiers, text, images, or graphs\n",
        "- Diffusion with preference optimization such as DPO or RLHF\n",
        "\n",
        "---\n",
        "\n",
        "### 3.2 Domain-Specific Applications\n",
        "\n",
        "**Computer Vision**\n",
        "- Super-resolution, inpainting, restoration, and translation\n",
        "- Semantic segmentation\n",
        "- Video generation\n",
        "- Point cloud generation\n",
        "- Anomaly detection\n",
        "\n",
        "**Natural Language Generation**\n",
        "\n",
        "**Multi-Modal Generation**\n",
        "- Text-to-image\n",
        "- Scene graph-to-image\n",
        "- Text-to-3D\n",
        "- Text-to-motion\n",
        "- Text-to-video\n",
        "- Text-to-audio\n",
        "\n",
        "**Temporal Data Modeling**\n",
        "- Time series imputation\n",
        "- Time series forecasting\n",
        "- Waveform signal processing\n",
        "\n",
        "**Robust Learning**\n",
        "- Data purification\n",
        "- Synthetic data generation\n",
        "\n",
        "**Interdisciplinary Applications**\n",
        "- Drug and molecular design\n",
        "- Material science\n",
        "- Medical image reconstruction\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Future Directions\n",
        "\n",
        "The final axis highlights open research challenges and directions.\n",
        "\n",
        "- Revisiting foundational assumptions\n",
        "- Achieving deeper theoretical understanding\n",
        "- Learning better latent representations\n",
        "- Developing diffusion foundation models and large-scale AIGC systems\n",
        "\n",
        "---\n",
        "\n",
        "## Key Takeaway\n",
        "\n",
        "Figure 1 presents diffusion models not as a single method, but as a modular and extensible paradigm:\n",
        "\n",
        "- Methodologically through sampling, likelihood, and data structure handling\n",
        "- Conceptually through connections to other generative models\n",
        "- Practically through applications across diverse domains\n",
        "- Strategically through clearly articulated future research directions\n",
        "\n",
        "This taxonomy clarifies why diffusion models have emerged as a central unifying framework in modern generative modeling.\n"
      ],
      "metadata": {
        "id": "e9EJiySVoubi"
      }
    }
  ]
}