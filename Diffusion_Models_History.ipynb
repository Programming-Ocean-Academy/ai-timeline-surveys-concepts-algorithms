{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Diffusion Models History\n",
        "\n",
        "## 1. What Are Diffusion Models?\n",
        "- A family of generative models used mainly for image generation.\n",
        "- They learn by **adding noise** to images step by step, then **learning to reverse** this noise to recreate clean images.\n",
        "- Modern text-to-image systems (Stable Diffusion, DALL-E 2, Midjourney, Imagen) use this technique.\n",
        "- They outperform VAEs, GANs, and PixelCNN due to higher stability and better image quality.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Intuition Behind Diffusion Models\n",
        "- Think of a drop of ink diffusing in water: structure slowly disappears into noise.\n",
        "- Diffusion models imitate this:\n",
        "  - Clean image → corrupted with noise → becomes pure Gaussian noise.\n",
        "  - The model then learns the **reverse process**: noise → structure → final image.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Main Applications\n",
        "- Image generation.\n",
        "- Inpainting (restoring missing regions).\n",
        "- Super-resolution.\n",
        "- Extensions to audio, molecules, and 3D generation.\n",
        "\n",
        "---\n",
        "\n",
        "# History and Theory (Simplified)\n",
        "\n",
        "## 4. Two Independent Origins\n",
        "\n",
        "### A. Physics-Inspired Diffusion (Sohl-Dickstein et al., 2015)\n",
        "- Modeled data corruption as physical diffusion.\n",
        "- Transform data into noise, then reverse the process.\n",
        "- Required modeling probability densities with normalization constants, which is computationally difficult.\n",
        "\n",
        "### B. Score-Based Models (Song & Ermon, 2019)\n",
        "- Modeled the **score**:  \n",
        "  $$s_\\theta(x) = \\nabla_x \\log p_\\theta(x)$$\n",
        "- Avoided computing normalization constants.\n",
        "- Used Gaussian perturbations and Langevin dynamics.\n",
        "- These ideas later unified with diffusion theory.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. DDPMs (2020–2021): The Breakthrough\n",
        "- Ho et al. (2020) introduced **Denoising Diffusion Probabilistic Models (DDPMs)**.\n",
        "- Showed diffusion can match or outperform GANs.\n",
        "- The model predicts noise instead of pixels.\n",
        "- Dhariwal & Nichol (2021): “Diffusion Models Beat GANs”.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Latent Diffusion (Stable Diffusion, 2022)\n",
        "- Instead of diffusing in pixel space, diffusion is performed in latent space.\n",
        "- Reduces computation, enabling fast and efficient image generation.\n",
        "- Allowed wide adoption in creative applications.\n",
        "\n",
        "---\n",
        "\n",
        "# How Diffusion Models Work (Simplified)\n",
        "\n",
        "## 7. Three Main Stages\n",
        "1. **Forward Process (Noise Addition)**  \n",
        "   Adds Gaussian noise over \\(T\\) steps until the image becomes pure noise.\n",
        "\n",
        "2. **Reverse Process (Learning to Denoise)**  \n",
        "   A neural network learns how to remove noise step by step.\n",
        "\n",
        "3. **Image Generation**  \n",
        "   Start from random noise and iteratively denoise.\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Forward Diffusion\n",
        "- A Markov chain:  \n",
        "  $$q(x_t \\mid x_{t-1}) = \\mathcal{N}(\\sqrt{1-\\beta_t}\\, x_{t-1}, \\beta_t I)$$\n",
        "- Noise level controlled by a schedule \\(\\beta_t\\).\n",
        "- Using closed-form reparameterization:  \n",
        "  $$x_t = \\sqrt{\\bar{\\alpha}_t}\\, x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\, \\epsilon$$  \n",
        "  which allows jumping directly to any step \\(t\\).\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Reverse Diffusion (Denoising)\n",
        "- Model predicts noise \\(\\epsilon_\\theta(x_t, t)\\) instead of the clean image.\n",
        "- Training objective:  \n",
        "  $$L = \\mathbb{E}\\|\\epsilon - \\epsilon_\\theta(x_t, t)\\|^2$$\n",
        "- Reconstruction step:  \n",
        "  $$x_{t-1} = \\frac{1}{\\sqrt{1-\\beta_t}}\\left(x_t - \\beta_t \\frac{\\epsilon_\\theta(x_t, t)}{\\sqrt{1-\\bar{\\alpha}_t}}\\right) + \\text{noise}$$\n",
        "\n",
        "---\n",
        "\n",
        "# Image Generation\n",
        "- Start with random Gaussian noise:  \n",
        "  $$x_T \\sim \\mathcal{N}(0, I)$$\n",
        "- Apply reverse denoising for \\(T\\) steps to obtain \\(x_0\\).\n",
        "- Fewer steps → faster but less detailed.  \n",
        "- More steps → higher quality but slower.\n",
        "\n",
        "---\n",
        "\n",
        "# Guided Diffusion\n",
        "\n",
        "## 10. Why Guidance?\n",
        "- Users need control over the generated output.\n",
        "\n",
        "### Types of Guidance\n",
        "**Classifier Guidance:**  \n",
        "Uses an external classifier; limited to predefined categories.\n",
        "\n",
        "**Classifier-Free Guidance (Stable Diffusion):**  \n",
        "- No external classifier.  \n",
        "- Works with arbitrary text prompts.  \n",
        "- Uses conditional and unconditional predictions:  \n",
        "  $$\\epsilon_{\\text{guided}} = \\epsilon_{\\text{uncond}} + w(\\epsilon_{\\text{cond}} - \\epsilon_{\\text{uncond}})$$  \n",
        "- \\(w\\) controls how strongly the text influences the generation.\n",
        "\n",
        "---\n",
        "\n",
        "# Latent Diffusion Models (LDMs)\n",
        "\n",
        "## 11. Why Latent Diffusion?\n",
        "- Pixel space is extremely large and costly.\n",
        "- Latent space is compressed and efficient.\n",
        "\n",
        "### Process\n",
        "1. Image → Encoder → latent \\(z\\)\n",
        "2. Diffusion happens in latent space: \\(z_t\\)\n",
        "3. Final latent decoded into an image.\n",
        "\n",
        "This is the core mechanism behind **Stable Diffusion**.\n",
        "\n",
        "---\n",
        "\n",
        "# Final Simple Summary\n",
        "- Diffusion models generate data by **learning to reverse noise**.\n",
        "- Inspired by physics and probabilistic modeling.\n",
        "- DDPMs unified diffusion and score-based ideas into a powerful generative framework.\n",
        "- Stable Diffusion introduced latent diffusion, enabling fast, accessible image generation.\n",
        "- Guidance methods allow precise text-to-image control.\n",
        "- Diffusion remains the leading technology in generative AI today.\n"
      ],
      "metadata": {
        "id": "xh9IhTIGJe_y"
      }
    }
  ]
}