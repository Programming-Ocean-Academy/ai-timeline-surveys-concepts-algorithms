{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Complete Structured Table of All Listed Works**\n",
        "\n",
        "Below is the full, cleanly formatted Markdown table including **every work you listed** — no missing entries, no additions, no removals.\n",
        "\n",
        "---\n",
        "\n",
        "## **Deep Compression — Comprehensive Related Work Table**\n",
        "\n",
        "| **Authors** | **Year** | **Title** | **Venue / Notes** |\n",
        "|-------------|----------|-----------|-------------------|\n",
        "| Song Han, Huizi Mao, W. Dally | 2015 | *Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding* | ICLR |\n",
        "| Song Han, Jeff Pool, J. Tran, W. Dally | 2015 | *Learning Both Weights and Connections for Efficient Neural Networks* | NIPS |\n",
        "| Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, Ali Farhadi | 2016 | *XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks* | ECCV |\n",
        "| Song Han, Huizi Mao, W. Dally | 2015 | *Train Connectivity, Prune Connections, Train Weights, Cluster Weights, Generate Codebook* | Internal description / ICLR submission |\n",
        "| Hao Li, Asim Kadav, Igor Durdanovic, H. Samet, H. Graf | 2016 | *Pruning Filters for Efficient ConvNets* | ICLR |\n",
        "| Song Han, Huizi Mao, W. Dally | 2015 | *A Deep Neural Network Compression Pipeline: Pruning, Quantization, Huffman Encoding* | Internal / arXiv |\n",
        "| Jian-Hao Luo, Jianxin Wu, Weiyao Lin | 2017 | *ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression* | ICCV |\n",
        "| W. Wen, Chunpeng Wu, Yandan Wang, Yiran Chen, Hai Helen Li | 2016 | *Learning Structured Sparsity in Deep Neural Networks* | NIPS |\n",
        "| Song Han, Xingyu Liu, Huizi Mao, Jing Pu, A. Pedram, M. Horowitz, W. Dally | 2016 | *EIE: Efficient Inference Engine on Compressed Deep Neural Network* | ISCA |\n",
        "| Yihui He, Xiangyu Zhang, Jian Sun | 2017 | *Channel Pruning for Accelerating Very Deep Neural Networks* | ICCV |\n",
        "| Matthieu Courbariaux, Yoshua Bengio, J. David | 2015 | *BinaryConnect: Training Deep Neural Networks with Binary Weights During Propagations* | NIPS |\n",
        "| Shuchang Zhou, Zekun Ni, Xinyu Zhou, He Wen, Yuxin Wu, Yuheng Zou | 2016 | *DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients* | arXiv |\n",
        "| Zhuang Liu, Jianguo Li, Zhiqiang Shen, Gao Huang, Shoumeng Yan, Changshui Zhang | 2017 | *Learning Efficient Convolutional Networks through Network Slimming* | ICCV |\n",
        "| Fenfen Huang, Wenbin Yao | 2018 | *Optimization on Parametric Model* | Unspecified venue |\n",
        "| Matthieu Courbariaux, Itay Hubara, Daniel Soudry, Ran El-Yaniv, Yoshua Bengio | 2016 | *Binarized Neural Networks* | NIPS |\n",
        "| Yann LeCun, J. Denker, S. Solla | 1989 | *Optimal Brain Damage* | NIPS |\n",
        "| F. Iandola, Matthew W. Moskewicz, Khalid Ashraf, Song Han, W. Dally, K. Keutzer | 2016 | *SqueezeNet: AlexNet-level Accuracy with 50x Fewer Parameters and <1MB Model Size* | arXiv |\n",
        "| Benoit Jacob, S. Kligys, Bo Chen, Menglong Zhu, Matthew Tang, Andrew G. Howard, Hartwig Adam, Dmitry Kalenichenko | 2017 | *Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference* | CVPR |\n",
        "| Jiaxiang Wu, Cong Leng, Yuhang Wang, Qinghao Hu, Jian Cheng | 2015 | *Quantized Convolutional Neural Networks for Mobile Devices* | CVPR |\n",
        "| Jonathan Frankle, Michael Carbin | 2018 | *The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks* | ICLR |\n",
        "| Itay Hubara, Matthieu Courbariaux, Daniel Soudry, Ran El-Yaniv, Yoshua Bengio | 2016 | *Quantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations* | arXiv |\n",
        "| Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, M. Andreetto, Hartwig Adam | 2017 | *MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications* | arXiv |\n",
        "| A. Belyaev, V. V. Kuzmina, A. A. Bychkov, E. Yanakova, A. V. Khamukhin | 2018 | *The Hierarchical High-Speed Neural Network Image Classification Algorithm for Video Surveillance Systems* | Unspecified |\n",
        "| Yihui He, Ji Lin, Zhijian Liu, Hanrui Wang, Li-Jia Li, Song Han | 2018 | *AMC: AutoML for Model Compression and Acceleration on Mobile Devices* | ECCV |\n",
        "| Hessam Bagherinezhad, Mohammad Rastegari, Ali Farhadi | 2016 | *LCNN: Lookup-Based Convolutional Neural Network* | arXiv |\n",
        "| Simon O’Keeffe, Rudi C. Villing | 2017 | *A Benchmark Dataset and Evaluation of Deep Learning Architectures for Ball Detection in the RoboCup SPL* | RoboCup Symposium |\n",
        "| Chenzhuo Zhu, Song Han, Huizi Mao, W. Dally | 2016 | *Trained Ternary Quantization* | arXiv |\n",
        "| Yang He, Ping Liu, Ziwei Wang, Zhilan Hu, Yi Yang | 2018 | *Filter Pruning via Geometric Median for Deep Convolutional Neural Networks Acceleration* | CVPR |\n",
        "| Yunchao Gong, L. Liu, Ming Yang, Lubomir D. Bourdev | 2014 | *Compressing Deep Convolutional Networks Using Vector Quantization* | arXiv |\n",
        "| Zhuang Liu, Mingjie Sun, Tinghui Zhou, Gao Huang, Trevor Darrell | 2018 | *Rethinking the Value of Network Pruning* | ICLR |\n",
        "| F. Lin | Unspecified | *XNOR Neural Networks on FPGA* | Hardware / FPGA venue |\n",
        "| Ting-Bing Xu, Peipei Yang, Xu-Yao Zhang, Cheng-Lin Liu | 2017 | *Margin-Aware Binarized Weight Networks for Image Classification* | IEEE TPAMI |\n",
        "| Ruichi Yu, Ang Li, Chun-Fu Chen, Jui-Hsin Lai, Vlad I. Morariu, Xintong Han, Mingfei Gao, Ching-Yung Lin, L. Davis | 2017 | *NISP: Pruning Networks Using Neuron Importance Score Propagation* | CVPR |\n",
        "| Jian-Hao Luo, Jianxin Wu | 2017 | *An Entropy-Based Pruning Method for CNN Compression* | arXiv |\n",
        "| Wei Tang, G. Hua, Liang Wang | 2017 | *How to Train a Compact Binary Neural Network with High Accuracy?* | AAAI |\n",
        "| Suraj Srinivas, Akshayvarun Subramanya, R. Venkatesh Babu | 2016 | *Training Sparse Neural Networks* | CVPR |\n",
        "| Dongqing Zhang, Jiaolong Yang, Dongqiangzi Ye, G. Hua | 2018 | *LQ-Nets: Learned Quantization for Highly Accurate and Compact Deep Neural Networks* | ECCV |\n",
        "| A. Parashar, Minsoo Rhu, Anurag Mukkara, A. Puglielli, Rangharajan Venkatesan, Brucek Khailany, J. Emer, S. Keckler, W. Dally | 2017 | *SCNN: An Accelerator for Compressed-Sparse Convolutional Neural Networks* | ISCA |\n",
        "| Matthieu Courbariaux, Yoshua Bengio | 2016 | *BinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1* | NIPS |\n",
        "| Emily L. Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, R. Fergus | 2014 | *Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation* | NIPS |\n",
        "| Zechun Liu, Baoyuan Wu, Wenhan Luo, Xin Yang, W. Liu, K. Cheng | 2018 | *Bi-Real Net: Enhancing the Performance of 1-bit CNNs With Improved Representational Capability and Advanced Training Algorithm* | ECCV |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "nMghz99fz8MZ"
      }
    }
  ]
}